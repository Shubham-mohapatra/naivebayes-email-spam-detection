{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO56W6Hltoir0+SvWQgl+1v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubham-mohapatra/naivebayes-email-spam-detection/blob/main/Naive_bayes_Spam_Email_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRsYh6V1IHnx",
        "outputId": "e61ccf73-968d-440b-fc1e-de4e8313436e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.155.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-httplib2) (0.22.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.25.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy scikit-learn nltk google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client flask joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('spam.csv',encoding='latin-1')\n",
        "df = df[['v1','v2']]\n",
        "df.rename(columns={'v1':'label','v2':'text'},inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqvCMGooIUx8",
        "outputId": "7d1514da-44c9-4139-fe3e-43c6b8e03636"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                               text\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean the text\n",
        "\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "  text = re.sub(r'\\W',' ',text) # for special chars\n",
        "  text = re.sub(r'\\d',' ',text) # remove the extra digits\n",
        "  text = re.sub(r'\\s+',' ',text) # removes the extra spaces\n",
        "  text = text.strip().lower()\n",
        "  return text\n",
        "\n",
        "\n",
        "df['text']  = df['text'].apply(clean_text)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41vlWOYjIU1M",
        "outputId": "8282b59c-f81c-407c-acf0-22fa9fb2597c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                               text\n",
            "0   ham  go until jurong point crazy available only in ...\n",
            "1   ham                            ok lar joking wif u oni\n",
            "2  spam  free entry in a wkly comp to win fa cup final ...\n",
            "3   ham        u dun say so early hor u c already then say\n",
            "4   ham  nah i don t think he goes to usf he lives arou...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the stopwords like \"is\",\"and\",\"the\"\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "  words = text.split()\n",
        "  filtered_words = [word for word in words if word not in stop_words]\n",
        "  return ' '.join(filtered_words)\n",
        "\n",
        "  df['text'] = df['text'].apply(remove_stopwords)\n",
        "  print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPdjDe_JIU4l",
        "outputId": "86b20573-4266-47fb-df57-45aef591211c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization og text into individual texts\n",
        "\n",
        "\n",
        "def tokenize_text(text):\n",
        "  return text.split()\n",
        "\n",
        "df['tokens'] = df['text'].apply(tokenize_text)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfWrwLAvLsOO",
        "outputId": "4d76859c-641d-4b84-e8dc-ccbd1117f747"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                               text  \\\n",
            "0   ham  go until jurong point crazy available only in ...   \n",
            "1   ham                            ok lar joking wif u oni   \n",
            "2  spam  free entry in a wkly comp to win fa cup final ...   \n",
            "3   ham        u dun say so early hor u c already then say   \n",
            "4   ham  nah i don t think he goes to usf he lives arou...   \n",
            "\n",
            "                                              tokens  \n",
            "0  [go, until, jurong, point, crazy, available, o...  \n",
            "1                     [ok, lar, joking, wif, u, oni]  \n",
            "2  [free, entry, in, a, wkly, comp, to, win, fa, ...  \n",
            "3  [u, dun, say, so, early, hor, u, c, already, t...  \n",
            "4  [nah, i, don, t, think, he, goes, to, usf, he,...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using stemming and lemmatization to further reduce the words to their base form\n",
        "\n",
        "# eg - \"running\" -> \"run\"\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#Stemming\n",
        "stemmer = PorterStemmer()\n",
        "def stem_text(text):\n",
        "  words = text.split()\n",
        "  words = [stemmer.stem(word) for word in words]\n",
        "  return ' '.join(words)\n",
        "\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpwRBe8FL-kP",
        "outputId": "83726603-1f6e-4f3b-8e5a-c0b32561f876"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                               text  \\\n",
            "0   ham  go until jurong point crazy available only in ...   \n",
            "1   ham                            ok lar joking wif u oni   \n",
            "2  spam  free entry in a wkly comp to win fa cup final ...   \n",
            "3   ham        u dun say so early hor u c already then say   \n",
            "4   ham  nah i don t think he goes to usf he lives arou...   \n",
            "\n",
            "                                              tokens  \n",
            "0  [go, until, jurong, point, crazy, available, o...  \n",
            "1                     [ok, lar, joking, wif, u, oni]  \n",
            "2  [free, entry, in, a, wkly, comp, to, win, fa, ...  \n",
            "3  [u, dun, say, so, early, hor, u, c, already, t...  \n",
            "4  [nah, i, don, t, think, he, goes, to, usf, he,...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['label'].map({'ham':0,'spam':1})\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgJOPHCXMuGc",
        "outputId": "2b80e398-a331-4503-844d-69cd50d63147"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                               text  \\\n",
            "0      0  go until jurong point crazy available only in ...   \n",
            "1      0                            ok lar joking wif u oni   \n",
            "2      1  free entry in a wkly comp to win fa cup final ...   \n",
            "3      0        u dun say so early hor u c already then say   \n",
            "4      0  nah i don t think he goes to usf he lives arou...   \n",
            "\n",
            "                                              tokens  \n",
            "0  [go, until, jurong, point, crazy, available, o...  \n",
            "1                     [ok, lar, joking, wif, u, oni]  \n",
            "2  [free, entry, in, a, wkly, comp, to, win, fa, ...  \n",
            "3  [u, dun, say, so, early, hor, u, c, already, t...  \n",
            "4  [nah, i, don, t, think, he, goes, to, usf, he,...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#spliting the dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(df['text'],df['label'],test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "yH7BTxHGmJJc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF Vetorization\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"TF-IDF vectorized training data shape : \",X_train_tfidf.shape)\n",
        "print(\"TF-IDF vectorized testing data shape : \",X_test_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJW1RIa9mPNO",
        "outputId": "9beede52-f674-47e3-b714-8c3f39f06b7f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF vectorized training data shape :  (4457, 6910)\n",
            "TF-IDF vectorized testing data shape :  (1115, 6910)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train naive bayes model\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf,y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "\n",
        "joblib.dump(model, 'spam_classifier_model.pkl')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCxkMdw8mgzX",
        "outputId": "77d2c9a8-4edf-4fe0-8fb1-a4e187c273a2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9560538116591928\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xG2LufsQs_km"
      }
    },
    {
      "source": [],
      "cell_type": "code",
      "metadata": {
        "id": "vjaqt9lWuaif"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jX4XVmEisBn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "43hk-BmfshGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sDFQbOb9yPeV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}